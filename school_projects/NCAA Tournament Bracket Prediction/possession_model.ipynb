{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA Tournament 2021 - Sean Norris, Mikayla Pugel, Ren Tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCAA tournament prediction using NCAA basketball game data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different model types to get predictions in before tournament officially starts on Thursday, 3/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  WFGM  WFGA  \\\n",
      "0    2003      10     1104      68     1328      62    N      0    27    58   \n",
      "1    2003      10     1272      70     1393      63    N      0    26    62   \n",
      "2    2003      11     1266      73     1437      61    N      0    24    58   \n",
      "3    2003      11     1296      56     1457      50    N      0    18    38   \n",
      "4    2003      11     1400      77     1208      71    N      0    30    61   \n",
      "\n",
      "   ...  LFGA3  LFTM  LFTA  LOR  LDR  LAst  LTO  LStl  LBlk  LPF  \n",
      "0  ...     10    16    22   10   22     8   18     9     2   20  \n",
      "1  ...     24     9    20   20   25     7   12     8     6   16  \n",
      "2  ...     26    14    23   31   22     9   12     2     5   23  \n",
      "3  ...     22     8    15   17   20     9   19     4     3   23  \n",
      "4  ...     16    17    27   21   15    12   10     7     1   14  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "Index(['Season', 'DayNum', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'WLoc',\n",
      "       'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR',\n",
      "       'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3',\n",
      "       'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "cities_df = pd.read_csv(\"2021_Data/Cities.csv\")\n",
    "teams_df = pd.read_csv(\"2021_Data/MTeams.csv\")\n",
    "reg_df = pd.read_csv(\"MRegularSeasonDetailedResults2021.csv\")\n",
    "\n",
    "print(reg_df.head(5))\n",
    "print(reg_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Games Per Season: \n",
      "    Season  WTeamID\n",
      "0     2003     4616\n",
      "1     2004     4571\n",
      "2     2005     4675\n",
      "3     2006     4757\n",
      "4     2007     5043\n",
      "5     2008     5163\n",
      "6     2009     5249\n",
      "7     2010     5263\n",
      "8     2011     5246\n",
      "9     2012     5253\n",
      "10    2013     5320\n",
      "11    2014     5362\n",
      "12    2015     5354\n",
      "13    2016     5369\n",
      "14    2017     5395\n",
      "15    2018     5405\n",
      "16    2019     5463\n",
      "17    2020     5328\n",
      "18    2021     3855\n",
      " \n"
     ]
    }
   ],
   "source": [
    "reg_df_test1 = copy.deepcopy(reg_df[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\"]])\n",
    "print(\"Number of Games Per Season: \")\n",
    "print(reg_df_test1[[\"WTeamID\",\"Season\"]].groupby(\"Season\").agg('count').reset_index())\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset for seasons since 2010:\n",
      "62613\n"
     ]
    }
   ],
   "source": [
    "reg_df2 = copy.deepcopy(reg_df[reg_df[\"Season\"]>=2010])\n",
    "reg_df3 = copy.deepcopy(reg_df2[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"WScore\",\"WFGA\",\"WFTA\",\"WOR\",\"WTO\",\"WBlk\",\"WPF\",\"LScore\",\"LFGA\",\"LFTA\",\"LOR\",\"LTO\",\"LBlk\",\"LPF\"]])\n",
    "print(\"Size of dataset for seasons since 2010:\")\n",
    "print(len(reg_df3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features using basketball stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Season  WTeamID  LTeamID WLoc  WScore  WPoss  LScore  LPoss   WBad  \\\n",
      "34074    2010     1143     1293    H      75   67.0      70   65.5   91.0   \n",
      "34075    2010     1314     1198    H      88   84.5      72   83.5  136.5   \n",
      "34076    2010     1326     1108    H     100   72.0      60   73.0   85.5   \n",
      "34077    2010     1393     1107    H      75   82.5      43   82.0  127.0   \n",
      "34078    2010     1143     1178    H      95   73.5      61   71.5   92.0   \n",
      "\n",
      "        LBad  W_Game_Pts_Per_Poss  L_Game_Pts_Per_Poss  \n",
      "34074  107.0             1.119403             1.068702  \n",
      "34075  145.0             1.041420             0.862275  \n",
      "34076  116.0             1.388889             0.821918  \n",
      "34077  181.5             0.909091             0.524390  \n",
      "34078  115.5             1.292517             0.853147  \n"
     ]
    }
   ],
   "source": [
    "# Create new stats for possessions and bad plays \n",
    "reg_df3[\"WPoss\"] = reg_df3[\"WFGA\"] + reg_df3[\"WFTA\"]/2.0 + reg_df3[\"WTO\"] - reg_df3[\"WOR\"]\n",
    "reg_df3[\"LPoss\"] = reg_df3[\"LFGA\"] + reg_df3[\"LFTA\"]/2.0 + reg_df3[\"LTO\"] - reg_df3[\"LOR\"]\n",
    "reg_df3[\"WBad\"] = reg_df3[\"WTO\"]*3 + reg_df3[\"WPF\"]/2.0 + reg_df3[\"LOR\"]*3 + reg_df3[\"LBlk\"]*5\n",
    "reg_df3[\"LBad\"] = reg_df3[\"LTO\"]*3 + reg_df3[\"LPF\"]/2.0 + reg_df3[\"WOR\"]*3 + reg_df3[\"WBlk\"]*5\n",
    "reg_df3[\"W_Game_Pts_Per_Poss\"] = reg_df3[\"WScore\"] / reg_df3[\"WPoss\"]\n",
    "reg_df3[\"L_Game_Pts_Per_Poss\"] = reg_df3[\"LScore\"] / reg_df3[\"LPoss\"]\n",
    "\n",
    "reg_df4 = copy.deepcopy(reg_df3[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"WScore\",\"WPoss\",\"LScore\",\"LPoss\",\"WBad\",\"LBad\",\"W_Game_Pts_Per_Poss\",\"L_Game_Pts_Per_Poss\"]])\n",
    "print(reg_df4.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Aggregated Stats: \n",
      "   Season  TeamID  TeamScore  TeamPoss  TeamBad  TeamGames  Team_PPP_SD  \\\n",
      "0    2010    1102       1613    1724.5   2563.5         29     0.156011   \n",
      "1    2010    1103       2344    2262.0   3242.0         33     0.114776   \n",
      "2    2010    1104       2192    2125.5   3328.5         32     0.104933   \n",
      "3    2010    1105       1468    1676.5   2998.5         23     0.159620   \n",
      "4    2010    1106       1793    1917.5   3014.5         28     0.175666   \n",
      "\n",
      "   Pts_Per_Poss  Poss_Per_Game  Bad_Per_Poss  \n",
      "0      0.935344      59.465517      0.743259  \n",
      "1      1.036251      68.545455      0.716622  \n",
      "2      1.031287      66.421875      0.782992  \n",
      "3      0.875634      72.891304      0.894274  \n",
      "4      0.935072      68.482143      0.786050  \n",
      " \n",
      "Team Opponent Aggregated Stats:\n",
      "   Season  TeamID  Opp_Score  Opp_Poss  Opp_Pts_Per_Poss\n",
      "0    2010    1102      61853   60692.0          1.019129\n",
      "1    2010    1103      68894   68996.0          0.998522\n",
      "2    2010    1104      71512   69291.0          1.032053\n",
      "3    2010    1105      43889   48054.5          0.913317\n",
      "4    2010    1106      53171   57639.5          0.922475\n"
     ]
    }
   ],
   "source": [
    "# Winners aggregation by season\n",
    "win_agg1 = reg_df4.groupby([\"Season\",\"WTeamID\"])[[\"WScore\",\"WPoss\",\"WBad\"]].sum().reset_index()\n",
    "win_agg2 = reg_df4[[\"Season\",\"WTeamID\",\"WScore\"]].groupby([\"Season\",\"WTeamID\"]).agg('count').reset_index()\n",
    "win_agg2.columns = [\"Season\",\"WTeamID\",\"games_played\"]\n",
    "win_agg3 = win_agg1.merge(win_agg2, how=\"left\", left_on=[\"Season\",\"WTeamID\"], right_on=[\"Season\",\"WTeamID\"])\n",
    "\n",
    "# Losers aggregation by season\n",
    "lose_agg1 = reg_df4.groupby([\"Season\",\"LTeamID\"])[[\"LScore\",\"LPoss\",\"LBad\"]].sum().reset_index()\n",
    "lose_agg2 = reg_df4[[\"Season\",\"LTeamID\",\"LScore\"]].groupby([\"Season\",\"LTeamID\"]).agg('count').reset_index()\n",
    "lose_agg2.columns = [\"Season\",\"LTeamID\",\"games_played\"]\n",
    "lose_agg3 = lose_agg1.merge(lose_agg2, how=\"left\", left_on=[\"Season\",\"LTeamID\"], right_on=[\"Season\",\"LTeamID\"])\n",
    "\n",
    "# Rename columns for groupings to have consistent names, then combine\n",
    "win_agg3.columns = [\"Season\",\"TeamID\",\"TeamScore\",\"TeamPoss\",\"TeamBad\",\"TeamGames\"]\n",
    "lose_agg3.columns = [\"Season\",\"TeamID\",\"TeamScore\",\"TeamPoss\",\"TeamBad\",\"TeamGames\"]\n",
    "team_agg1 = win_agg3.append(lose_agg3)\n",
    "\n",
    "# Get aggregate sum of points, possessions, bad plays and games played for each team\n",
    "team_agg2 = team_agg1.groupby([\"Season\",\"TeamID\"])[[\"TeamScore\",\"TeamPoss\",\"TeamBad\",\"TeamGames\"]].sum().reset_index()\n",
    "\n",
    "# Get standard deviation of points per possession for each team\n",
    "win_agg4 = reg_df4[[\"Season\",\"WTeamID\",\"W_Game_Pts_Per_Poss\"]]\n",
    "win_agg4.columns = [\"Season\",\"TeamID\",\"Game_Pts_Per_Poss\"]\n",
    "lose_agg4 = reg_df4[[\"Season\",\"LTeamID\",\"L_Game_Pts_Per_Poss\"]]\n",
    "lose_agg4.columns = [\"Season\",\"TeamID\",\"Game_Pts_Per_Poss\"]\n",
    "team_agg3 = copy.deepcopy(win_agg4.append(lose_agg4))\n",
    "team_agg4 = team_agg3.groupby([\"Season\",\"TeamID\"]).agg(np.std).reset_index()\n",
    "team_agg5 = team_agg2.merge(team_agg4, how=\"left\", left_on=[\"Season\",\"TeamID\"], right_on=[\"Season\",\"TeamID\"])\n",
    "team_agg5.columns = [\"Season\",\"TeamID\",\"TeamScore\",\"TeamPoss\",\"TeamBad\",\"TeamGames\",\"Team_PPP_SD\"]\n",
    "\n",
    "# Calculate points per possession, possessions per game, and bad plays per possession stats for each team\n",
    "team_agg5[\"Pts_Per_Poss\"] = team_agg5[\"TeamScore\"] / team_agg5[\"TeamPoss\"]\n",
    "team_agg5[\"Poss_Per_Game\"] = team_agg5[\"TeamPoss\"] / team_agg5[\"TeamGames\"]\n",
    "team_agg5[\"Bad_Per_Poss\"] = team_agg5[\"TeamBad\"] / (team_agg5[\"TeamPoss\"] * 2)\n",
    "\n",
    "print(\"Team Aggregated Stats: \")\n",
    "print(team_agg5.head(5))\n",
    "print(\" \")\n",
    "\n",
    "# Using original full schedule, add opponent points and possessions data\n",
    "reg_df4a = reg_df4.merge(team_agg2, how='left', left_on=[\"Season\",\"LTeamID\"], right_on=[\"Season\",\"TeamID\"])\n",
    "reg_df4b = copy.deepcopy(reg_df4a[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"TeamScore\",\"TeamPoss\"]])\n",
    "reg_df4b.columns = [\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Opp_Score\",\"W_Opp_Poss\"]\n",
    "reg_df4c = reg_df4b.merge(team_agg2, how='left', left_on=[\"Season\",\"WTeamID\"], right_on=[\"Season\",\"TeamID\"])\n",
    "reg_df4d = copy.deepcopy(reg_df4c[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Opp_Score\",\"W_Opp_Poss\",\"TeamScore\",\"TeamPoss\"]])\n",
    "reg_df4d.columns = [\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Opp_Score\",\"W_Opp_Poss\",\"L_Opp_Score\",\"L_Opp_Poss\"]\n",
    "\n",
    "# Split into winners and losers aggregation by season for opponent points and possession\n",
    "win_opp_agg1 = reg_df4d.groupby([\"Season\",\"WTeamID\"])[[\"W_Opp_Score\",\"W_Opp_Poss\"]].sum().reset_index()\n",
    "lose_opp_agg1 = reg_df4d.groupby([\"Season\",\"LTeamID\"])[[\"L_Opp_Score\",\"L_Opp_Poss\"]].sum().reset_index()\n",
    "\n",
    "# Rename columns for groupings to have consistent names, then combine\n",
    "win_opp_agg1.columns = [\"Season\",\"TeamID\",\"Opp_Score\",\"Opp_Poss\"]\n",
    "lose_opp_agg1.columns = [\"Season\",\"TeamID\",\"Opp_Score\",\"Opp_Poss\"]\n",
    "opp_agg1 = win_opp_agg1.append(lose_opp_agg1)\n",
    "\n",
    "# Get aggregate sum of opponent points and possessions for each team\n",
    "opp_agg2 = opp_agg1.groupby([\"Season\",\"TeamID\"])[[\"Opp_Score\",\"Opp_Poss\"]].sum().reset_index()\n",
    "\n",
    "# Calculate opponent points per possession for each team\n",
    "opp_agg2[\"Opp_Pts_Per_Poss\"] = opp_agg2[\"Opp_Score\"] / opp_agg2[\"Opp_Poss\"]\n",
    "\n",
    "print(\"Team Opponent Aggregated Stats:\")\n",
    "print(opp_agg2.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used for modeling:\n",
      "['Pts_Per_Poss_Diff', 'Opp_Pts_Per_Poss_Diff', 'Poss_Per_Game_Diff', 'Location', 'PPP_SD_Diff', 'Bad_Per_Poss_Diff']\n",
      " \n",
      "Sample of feature values in training set:\n",
      "[[-0.71087079 -0.29569093 -0.70852576  0.          1.03357011 -0.36999847]\n",
      " [ 0.5059096  -1.49354652 -1.109481    1.          0.30963304 -0.90119719]\n",
      " [-0.40591225  1.31730696 -1.29476403  1.          0.85128228  0.48649496]\n",
      " [ 2.0518106   0.76849523  1.0233721   1.         -0.34333088 -1.95037123]\n",
      " [-0.17534843  0.39451785 -1.66381665 -1.          0.01047746  0.90368145]\n",
      " [ 0.37944904  0.39396855  0.35943065 -1.          1.05512011 -0.53070865]\n",
      " [ 1.6506352   0.93215518  0.97084961  1.         -0.49707964 -1.29501233]\n",
      " [ 0.55124822 -0.15862069  0.28136063 -1.         -0.73561906  0.84118193]\n",
      " [-1.53763054 -0.13404918  0.19693757 -1.          0.24388712  3.09229878]\n",
      " [-0.86132949  0.36793551  0.75963709 -1.          0.77455344 -1.05686522]]\n",
      " \n",
      "Sample of outcome values in training set: \n",
      "[0 0 1 1 0 1 1 1 0 1]\n",
      "62000\n",
      "613\n",
      "62000\n",
      "613\n"
     ]
    }
   ],
   "source": [
    "# Using original full schedule, add winning team points per possession, possessions per game, bad plays per possession, PPP_SD\n",
    "reg_df5 = reg_df4.merge(team_agg5, how='left', left_on=[\"Season\",\"WTeamID\"], right_on=[\"Season\",\"TeamID\"])\n",
    "reg_df6 = copy.deepcopy(reg_df5[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"Pts_Per_Poss\",\"Poss_Per_Game\",\"Bad_Per_Poss\",\"Team_PPP_SD\"]])\n",
    "reg_df6.columns = [\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Pts_Per_Poss\",\"W_Poss_Per_Game\",\"W_Bad_Per_Poss\",\"W_PPP_SD\"]\n",
    "\n",
    "# Using original full schedule, add losing team points per possession, possessions per game, bad plays per possession, PPP_SD\n",
    "reg_df7 = reg_df6.merge(team_agg5, how='left', left_on=[\"Season\",\"LTeamID\"], right_on=[\"Season\",\"TeamID\"])\n",
    "reg_df8 = copy.deepcopy(reg_df7[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Pts_Per_Poss\",\"W_Poss_Per_Game\",\"W_Bad_Per_Poss\",\"W_PPP_SD\",\n",
    "                                 \"Pts_Per_Poss\",\"Poss_Per_Game\",\"Bad_Per_Poss\",\"Team_PPP_SD\"]])\n",
    "reg_df8.columns = [\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Pts_Per_Poss\",\"W_Poss_Per_Game\",\"W_Bad_Per_Poss\",\"W_PPP_SD\",\n",
    "                   \"L_Pts_Per_Poss\",\"L_Poss_Per_Game\",\"L_Bad_Per_Poss\",\"L_PPP_SD\"]\n",
    "\n",
    "# Using original full schedule, add winning and losing team opponent points per possession\n",
    "reg_df8a = reg_df8.merge(opp_agg2, how='left', left_on=[\"Season\",\"WTeamID\"], right_on=[\"Season\",\"TeamID\"])\n",
    "reg_df8b = copy.deepcopy(reg_df8a[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Pts_Per_Poss\",\"W_Poss_Per_Game\",\"W_Bad_Per_Poss\",\"W_PPP_SD\",\n",
    "                                   \"L_Pts_Per_Poss\",\"L_Poss_Per_Game\",\"L_Bad_Per_Poss\",\"L_PPP_SD\",\"Opp_Pts_Per_Poss\"]])\n",
    "reg_df8b.columns = [\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Pts_Per_Poss\",\"W_Poss_Per_Game\",\"W_Bad_Per_Poss\",\"W_PPP_SD\",\n",
    "                    \"L_Pts_Per_Poss\",\"L_Poss_Per_Game\",\"L_Bad_Per_Poss\",\"L_PPP_SD\",\"W_Opp_Pts_Per_Poss\"]\n",
    "reg_df8c = reg_df8b.merge(opp_agg2, how='left', left_on=[\"Season\",\"LTeamID\"], right_on=[\"Season\",\"TeamID\"])\n",
    "reg_df8d = copy.deepcopy(reg_df8c[[\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Pts_Per_Poss\",\"W_Poss_Per_Game\",\"W_Bad_Per_Poss\",\"W_PPP_SD\",\n",
    "                                   \"L_Pts_Per_Poss\",\"L_Poss_Per_Game\",\"L_Bad_Per_Poss\",\"L_PPP_SD\",\"W_Opp_Pts_Per_Poss\",\"Opp_Pts_Per_Poss\"]])\n",
    "reg_df8d.columns = [\"Season\",\"WTeamID\",\"LTeamID\",\"WLoc\",\"W_Pts_Per_Poss\",\"W_Poss_Per_Game\",\"W_Bad_Per_Poss\",\"W_PPP_SD\",\n",
    "                    \"L_Pts_Per_Poss\",\"L_Poss_Per_Game\",\"L_Bad_Per_Poss\",\"L_PPP_SD\",\"W_Opp_Pts_Per_Poss\",\"L_Opp_Pts_Per_Poss\"]\n",
    "\n",
    "# Map Winner Location variable to 1 for H, 0 for N, -1 for A\n",
    "location_map = {\"H\":1, \"N\":0, \"A\":-1}\n",
    "reg_df8d['WLoc_Mapped'] = reg_df8d[\"WLoc\"].map(location_map)\n",
    "\n",
    "# Split full schedule into DFs of perspective of team with lower Team ID number\n",
    "wteam_lower = copy.deepcopy(reg_df8d[reg_df8d[\"WTeamID\"]<reg_df8d[\"LTeamID\"]])\n",
    "lteam_lower = copy.deepcopy(reg_df8d[reg_df8d[\"WTeamID\"]>reg_df8d[\"LTeamID\"]])\n",
    "\n",
    "# Add game_result column: 1 for win, 0 for loss\n",
    "wteam_lower[\"Game_Result\"] = 1\n",
    "lteam_lower[\"Game_Result\"] = 0\n",
    "\n",
    "# Calculate points per possession, possessions per game, bad plays per possession, opponent points per possession difference from winner/loser perspective\n",
    "wteam_lower[\"Pts_Per_Poss_Diff\"] = wteam_lower[\"W_Pts_Per_Poss\"] - wteam_lower[\"L_Pts_Per_Poss\"]\n",
    "lteam_lower[\"Pts_Per_Poss_Diff\"] = lteam_lower[\"L_Pts_Per_Poss\"] - lteam_lower[\"W_Pts_Per_Poss\"]\n",
    "wteam_lower[\"Poss_Per_Game_Diff\"] = wteam_lower[\"W_Poss_Per_Game\"] - wteam_lower[\"L_Poss_Per_Game\"]\n",
    "lteam_lower[\"Poss_Per_Game_Diff\"] = lteam_lower[\"L_Poss_Per_Game\"] - lteam_lower[\"W_Poss_Per_Game\"]\n",
    "wteam_lower[\"Bad_Per_Poss_Diff\"] = wteam_lower[\"W_Bad_Per_Poss\"] - wteam_lower[\"L_Bad_Per_Poss\"]\n",
    "lteam_lower[\"Bad_Per_Poss_Diff\"] = lteam_lower[\"L_Bad_Per_Poss\"] - lteam_lower[\"W_Bad_Per_Poss\"]\n",
    "wteam_lower[\"PPP_SD_Diff\"] = wteam_lower[\"W_PPP_SD\"] - wteam_lower[\"L_PPP_SD\"]\n",
    "lteam_lower[\"PPP_SD_Diff\"] = lteam_lower[\"L_PPP_SD\"] - lteam_lower[\"W_PPP_SD\"]\n",
    "wteam_lower[\"Opp_Pts_Per_Poss_Diff\"] = wteam_lower[\"W_Opp_Pts_Per_Poss\"] - wteam_lower[\"L_Opp_Pts_Per_Poss\"]\n",
    "lteam_lower[\"Opp_Pts_Per_Poss_Diff\"] = lteam_lower[\"L_Opp_Pts_Per_Poss\"] - lteam_lower[\"W_Opp_Pts_Per_Poss\"]\n",
    "\n",
    "# Convert location to winner/loser perspective\n",
    "wteam_lower[\"Location\"] = wteam_lower[\"WLoc_Mapped\"]\n",
    "lteam_lower[\"Location\"] = lteam_lower[\"WLoc_Mapped\"] * -1\n",
    "\n",
    "# Recombine DFs to create full dataset of features and outcome variable\n",
    "reg_df9 = copy.deepcopy(wteam_lower.append(lteam_lower))\n",
    "\n",
    "# Shuffle schedule into random order, then transform feature values to standardized normal scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "reg_final1 = copy.deepcopy(reg_df9.sample(frac=1, random_state=7))\n",
    "reg_final1[\"Pts_Per_Poss_Diff\"] = scaler.fit_transform(np.array(reg_final1[\"Pts_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "reg_final1[\"Poss_Per_Game_Diff\"] = scaler.fit_transform(np.array(reg_final1[\"Poss_Per_Game_Diff\"]).reshape(-1,1))\n",
    "reg_final1[\"Bad_Per_Poss_Diff\"] = scaler.fit_transform(np.array(reg_final1[\"Bad_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "reg_final1[\"PPP_SD_Diff\"] = scaler.fit_transform(np.array(reg_final1[\"PPP_SD_Diff\"]).reshape(-1,1))\n",
    "reg_final1[\"Opp_Pts_Per_Poss_Diff\"] = scaler.fit_transform(np.array(reg_final1[\"Opp_Pts_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "\n",
    "# Get X predictor variables and split into train and test sets\n",
    "X_features = [\"Pts_Per_Poss_Diff\",\"Opp_Pts_Per_Poss_Diff\",\"Poss_Per_Game_Diff\",\"Location\",\"PPP_SD_Diff\",\"Bad_Per_Poss_Diff\"]\n",
    "reg_X = np.array(reg_final1[X_features])\n",
    "reg_X_train = reg_X[0:62000]\n",
    "reg_X_test = reg_X[62000:]\n",
    "\n",
    "# Get Y outcome variable and split into train and test sets\n",
    "reg_Y = np.array(reg_final1[[\"Game_Result\"]]).reshape(-1)\n",
    "reg_Y_train = reg_Y[0:62000]\n",
    "reg_Y_test = reg_Y[62000:]\n",
    "\n",
    "# Display samples of X and Y data\n",
    "print(\"Features used for modeling:\")\n",
    "print(X_features)\n",
    "print(\" \")\n",
    "print(\"Sample of feature values in training set:\")\n",
    "print(reg_X_train[0:10])\n",
    "print(\" \")\n",
    "print(\"Sample of outcome values in training set: \")\n",
    "print(reg_Y_train[0:10])\n",
    "\n",
    "print(len(reg_X_train))\n",
    "print(len(reg_X_test))\n",
    "print(len(reg_Y_train))\n",
    "print(len(reg_Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Preliminary Models to Get Sense of Modeling Options and Potential Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Coefficient Values: \n",
      "                                          Variable  Coefficient\n",
      "0          Offensive Efficiency: Pts Per Poss Diff     1.221873\n",
      "1  Defensive Efficiency: Pts Per Poss Allowed Diff     0.332447\n",
      "2                        Tempo: Poss Per Game Diff    -0.138246\n",
      "3                             Home Court Advantage     0.629619\n",
      "4       Offensive Volatility: Pts Per Poss SD Diff    -0.071926\n",
      "5           Mistake-Prone: Bad Plays Per Poss Diff    -0.011393\n",
      " \n",
      "F1 Score - Logistic Regression: 0.7699099180946478\n",
      "F1 Score - Random Forest: 0.7699099180946478\n",
      "F1 Score - Gradient Boosting: 0.7763248386128256\n",
      "F1 Score - Naive Bayes: 0.748666372714145\n",
      "F1 Score - KNN: 0.7307456488341624\n",
      "F1 Score - Voting Ensemble of Above 5 Models: 0.7731736071996883\n"
     ]
    }
   ],
   "source": [
    "# Set up logistic regression model\n",
    "lr1 = LogisticRegression(C=0.1, random_state=7)\n",
    "lr1.fit(reg_X_train, reg_Y_train)\n",
    "lr1_pred = lr1.predict(reg_X_test)\n",
    "lr1_coef = pd.DataFrame(data={\"Variable\":[\"Offensive Efficiency: Pts Per Poss Diff\",\"Defensive Efficiency: Pts Per Poss Allowed Diff\",\n",
    "                                          \"Tempo: Poss Per Game Diff\",\"Home Court Advantage\",\"Offensive Volatility: Pts Per Poss SD Diff\",\n",
    "                                          \"Mistake-Prone: Bad Plays Per Poss Diff\"],\n",
    "                              \"Coefficient\":lr1.coef_.reshape(-1)})\n",
    "print(\"Logistic Regression Coefficient Values: \")\n",
    "print(lr1_coef)\n",
    "print(\" \")\n",
    "print(\"F1 Score - Logistic Regression:\", f1_score(reg_Y_test, lr1_pred, average = 'weighted'))\n",
    "\n",
    "# Set up random forest model\n",
    "rf1 = RandomForestClassifier(n_estimators=1000, criterion=\"entropy\", max_features=None, max_samples=0.01, random_state=7)\n",
    "rf1.fit(reg_X_train, reg_Y_train)\n",
    "rf1_pred = rf1.predict(reg_X_test)\n",
    "print(\"F1 Score - Random Forest:\", f1_score(reg_Y_test, rf1_pred, average = 'weighted'))\n",
    "\n",
    "# Set up gradient boosting model\n",
    "gb1 = GradientBoostingClassifier(n_estimators=100, max_features=None, learning_rate=0.1, subsample=0.3, random_state=7)\n",
    "gb1.fit(reg_X_train, reg_Y_train)\n",
    "gb1_pred = gb1.predict(reg_X_test)\n",
    "print(\"F1 Score - Gradient Boosting:\", f1_score(reg_Y_test, gb1_pred, average = 'weighted'))\n",
    "\n",
    "# Set up naive bayes model\n",
    "nb1 = BernoulliNB()\n",
    "nb1.fit(reg_X_train, reg_Y_train)\n",
    "nb1_pred = nb1.predict(reg_X_test)\n",
    "print(\"F1 Score - Naive Bayes:\", f1_score(reg_Y_test, nb1_pred, average = 'weighted'))\n",
    "\n",
    "# Set up KNN model\n",
    "knn1 = KNeighborsClassifier(n_neighbors=9)\n",
    "knn1.fit(reg_X_train, reg_Y_train)\n",
    "knn1_pred = knn1.predict(reg_X_test)\n",
    "print(\"F1 Score - KNN:\", f1_score(reg_Y_test, knn1_pred, average = 'weighted'))\n",
    "\n",
    "# Set up ensemble voting classifier\n",
    "voter = VotingClassifier(estimators=[(\"LR\",lr1),(\"RF\",rf1),(\"GB\",gb1),(\"NB\",nb1),(\"KNN\",knn1)], voting=\"hard\")\n",
    "voter.fit(reg_X_train, reg_Y_train)\n",
    "voter_pred = voter.predict(reg_X_test)\n",
    "print(\"F1 Score - Voting Ensemble of Above 5 Models:\", f1_score(reg_Y_test, voter_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps: Predict the Tournament?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    seed_line Seed  overall_seed  TeamID      TeamName\n",
      "0           1  W01             4    1276      Michigan\n",
      "1           2  W02             5    1104       Alabama\n",
      "2           3  W03            11    1400         Texas\n",
      "3           4  W04            13    1199    Florida St\n",
      "4           5  W05            20    1160      Colorado\n",
      "..        ...  ...           ...     ...           ...\n",
      "63         12  Z12            49    1457      Winthrop\n",
      "64         13  Z13            52    1317   North Texas\n",
      "65         14  Z14            57    1159       Colgate\n",
      "66         15  Z15            61    1331  Oral Roberts\n",
      "67         16  Z16            64    1216      Hartford\n",
      "\n",
      "[68 rows x 5 columns]\n",
      "    tm1_seed_num tm1_Seed  tm1_ID tm2_Seed  tm2_seed_num  tm2_ID\n",
      "0             16     W16b    1411     W16a            16  1291.0\n",
      "1             11     X11a    1179     X11b            11  1455.0\n",
      "2             16     X16a    1111     X16b            16  1313.0\n",
      "3             11     W11b    1417     W11a            11  1277.0\n",
      "4              7      Z07    1196      Z10            10  1439.0\n",
      "5              3      Z03    1116      Z14            14  1159.0\n",
      "6              1      Y01    1228      Y16            16  1180.0\n",
      "7              6      Z06    1403      Z11            11  1429.0\n",
      "8              2      Z02    1326      Z15            15  1331.0\n",
      "9              1      Z01    1124      Z16            16  1216.0\n",
      "10             8      Y08    1260      Y09             9  1210.0\n",
      "11             5      Y05    1397      Y12            12  1333.0\n",
      "12             4      Y04    1329      Y13            13  1251.0\n",
      "13             8      Z08    1314      Z09             9  1458.0\n",
      "14             2      Y02    1222      Y15            15  1156.0\n",
      "15             4      Z04    1345      Z13            13  1317.0\n",
      "16             7      Y07    1155      Y10            10  1353.0\n",
      "17             6      Y06    1361      Y11            11  1393.0\n",
      "18             3      Y03    1452      Y14            14  1287.0\n",
      "19             5      Z05    1437      Z12            12  1457.0\n",
      "20             5      W05    1160      W12            12  1207.0\n",
      "21             4      W04    1199      W13            13  1422.0\n",
      "22             3      X03    1242      X14            14  1186.0\n",
      "23             8      W08    1261      W09             9  1382.0\n",
      "24             1      W01    1276      W16            16     NaN\n",
      "25             5      X05    1166      X12            12  1364.0\n",
      "26             2      W02    1104      W15            15  1233.0\n",
      "27             6      X06    1425      X11            11     NaN\n",
      "28             2      X02    1234      X15            15  1213.0\n",
      "29             7      W07    1163      W10            10  1268.0\n",
      "30             4      X04    1438      X13            13  1325.0\n",
      "31             8      X08    1328      X09             9  1281.0\n",
      "32             1      X01    1211      X16            16     NaN\n",
      "33             6      W06    1140      W11            11     NaN\n",
      "34             3      W03    1400      W14            14  1101.0\n",
      "35             7      X07    1332      X10            10  1433.0\n"
     ]
    }
   ],
   "source": [
    "# Read in and clean up tourney data\n",
    "tourney_seeds = pd.read_csv(\"tourney_seeds.csv\")\n",
    "tourney_seeds = tourney_seeds[[\"seed_line\", \"Seed\", \"overall_seed\", \"TeamID\", \"TeamName\"]]\n",
    "\n",
    "round_1 = pd.read_csv(\"Round_1_2021.csv\")\n",
    "round_1 = round_1[[\"tm1_seed_num\", \"tm1_Seed\", \"tm1_ID\", \"tm2_Seed\", \"tm2_seed_num\", \"tm2_ID\"]]\n",
    "round_1 = round_1[0:36][:]\n",
    "\n",
    "print(tourney_seeds)\n",
    "print(round_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Team1  Team2\n",
      "1   1101   1104\n",
      "2   1101   1111\n",
      "3   1101   1116\n",
      "4   1101   1124\n",
      "5   1101   1140\n",
      "2278\n"
     ]
    }
   ],
   "source": [
    "# Get 2021 regular season data only\n",
    "team_agg2021 = copy.deepcopy(team_agg5[team_agg5[\"Season\"]==2021])\n",
    "opp_agg2021 = copy.deepcopy(opp_agg2[opp_agg2[\"Season\"]==2021])\n",
    "\n",
    "# Create dataframe of possible 2021 tournament matchups\n",
    "tourney_ids = list(copy.deepcopy(tourney_seeds[\"TeamID\"].sort_values()))\n",
    "\n",
    "team1_list = []\n",
    "for i in tourney_ids:\n",
    "    for j in range(68):\n",
    "        team1_list.append(i)\n",
    "\n",
    "team2_list = []\n",
    "for x in range(68):\n",
    "    for y in tourney_ids:\n",
    "        team2_list.append(y)\n",
    "        \n",
    "tourney_matchups1 = pd.DataFrame(data={\"Team1\":team1_list, \"Team2\":team2_list})\n",
    "tourney_matchups2 = copy.deepcopy(tourney_matchups1[tourney_matchups1[\"Team1\"] < tourney_matchups1[\"Team2\"]])\n",
    "print(tourney_matchups2.head(5))\n",
    "print(len(tourney_matchups2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used for modeling:\n",
      "['Pts_Per_Poss_Diff', 'Opp_Pts_Per_Poss_Diff', 'Poss_Per_Game_Diff', 'Location', 'PPP_SD_Diff', 'Bad_Per_Poss_Diff']\n",
      " \n",
      "Sample of feature values in 2021 tourney test set:\n",
      "[[ 0.10601457 -1.70677407 -1.0732056   0.         -0.8274211  -0.88807454]\n",
      " [ 0.70840791 -0.35802369  0.72759943  0.         -0.6846905  -0.75822741]\n",
      " [-0.33856701 -1.30906444 -1.15887142  0.         -1.45625667  0.50236517]\n",
      " [-1.8206764  -0.74401012 -0.01514151  0.         -1.04309444 -0.30125366]\n",
      " [-0.48308094 -2.06254953 -0.01167842  0.         -1.21494109  1.04434167]\n",
      " [ 0.66791766 -1.659582    1.40278245  0.          0.25266328  0.17523639]\n",
      " [ 0.45928775 -2.37274908  0.2733322   0.         -1.41000278 -0.14862455]\n",
      " [-1.83775645 -0.73873628 -0.36600686  0.          0.18433279  1.28371774]\n",
      " [-0.63896347 -1.35931836  1.06297203  0.         -0.05254865  0.91017314]\n",
      " [-0.24010362 -1.14950131  0.77233787  0.         -0.30504474  0.46290022]]\n",
      " \n",
      "2278\n",
      "[0.42345421 0.64910928 0.33662234 ... 0.21212886 0.24771824 0.50847017]\n",
      "(2278,)\n",
      "[0 1 0 ... 0 0 1]\n",
      "0.019991481433946634\n",
      "0.9854635034560507\n"
     ]
    }
   ],
   "source": [
    "# Using full tourney matchups, add Team 1 points per possession, possessions per game, bad plays per possession, PPP_SD\n",
    "tourney_matchups3 = tourney_matchups2.merge(team_agg2021, how='left', left_on=\"Team1\", right_on=\"TeamID\")\n",
    "tourney_matchups4 = copy.deepcopy(tourney_matchups3[[\"Team1\",\"Team2\",\"Pts_Per_Poss\",\"Poss_Per_Game\",\"Bad_Per_Poss\",\"Team_PPP_SD\"]])\n",
    "tourney_matchups4.columns = [\"Team1\",\"Team2\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\"]\n",
    "\n",
    "# Using full tourney matchups, add Team 2 points per possession, possessions per game, bad plays per possession, PPP_SD\n",
    "tourney_matchups5 = tourney_matchups4.merge(team_agg2021, how='left', left_on=\"Team2\", right_on=\"TeamID\")\n",
    "tourney_matchups6 = copy.deepcopy(tourney_matchups5[[\"Team1\",\"Team2\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\n",
    "                                                     \"Pts_Per_Poss\",\"Poss_Per_Game\",\"Bad_Per_Poss\",\"Team_PPP_SD\"]])\n",
    "tourney_matchups6.columns = [\"Team1\",\"Team2\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\n",
    "                             \"T2_Pts_Per_Poss\",\"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\"]\n",
    "\n",
    "# Using full tourney matchups, add Team 1 and Team 2 opponent points per possession\n",
    "tourney_matchups7 = tourney_matchups6.merge(opp_agg2021, how='left', left_on=\"Team1\", right_on=\"TeamID\")\n",
    "tourney_matchups7a = copy.deepcopy(tourney_matchups7[[\"Team1\",\"Team2\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\n",
    "                                                      \"T2_Pts_Per_Poss\",\"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\",\"Opp_Pts_Per_Poss\"]])\n",
    "tourney_matchups7a.columns = [\"Team1\",\"Team2\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\n",
    "                              \"T2_Pts_Per_Poss\",\"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\",\"T1_Opp_Pts_Per_Poss\"]\n",
    "tourney_matchups7b = tourney_matchups7a.merge(opp_agg2021, how='left', left_on=\"Team2\", right_on=\"TeamID\")\n",
    "tourney_matchups7c = copy.deepcopy(tourney_matchups7b[[\"Team1\",\"Team2\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\"T2_Pts_Per_Poss\",\n",
    "                                                       \"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\",\"T1_Opp_Pts_Per_Poss\",\"Opp_Pts_Per_Poss\"]])\n",
    "tourney_matchups7c.columns = [\"Team1\",\"Team2\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\"T2_Pts_Per_Poss\",\n",
    "                              \"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\",\"T1_Opp_Pts_Per_Poss\",\"T2_Opp_Pts_Per_Poss\"]\n",
    "\n",
    "# Give neutral location for each matchup\n",
    "tourney_matchups7c[\"Location\"] = 0\n",
    "\n",
    "# Calculate points per possession, possessions per game, bad plays per possession, opponent points per possession difference from Team 1 perspective\n",
    "tourney_matchups7c[\"Pts_Per_Poss_Diff\"] = tourney_matchups7c[\"T1_Pts_Per_Poss\"] - tourney_matchups7c[\"T2_Pts_Per_Poss\"]\n",
    "tourney_matchups7c[\"Poss_Per_Game_Diff\"] = tourney_matchups7c[\"T1_Poss_Per_Game\"] - tourney_matchups7c[\"T2_Poss_Per_Game\"]\n",
    "tourney_matchups7c[\"Bad_Per_Poss_Diff\"] = tourney_matchups7c[\"T1_Bad_Per_Poss\"] - tourney_matchups7c[\"T2_Bad_Per_Poss\"]\n",
    "tourney_matchups7c[\"PPP_SD_Diff\"] = tourney_matchups7c[\"T1_PPP_SD\"] - tourney_matchups7c[\"T2_PPP_SD\"]\n",
    "tourney_matchups7c[\"Opp_Pts_Per_Poss_Diff\"] = tourney_matchups7c[\"T1_Opp_Pts_Per_Poss\"] - tourney_matchups7c[\"T2_Opp_Pts_Per_Poss\"]\n",
    "\n",
    "# Transform feature values to standardized normal scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "tourney_final = copy.deepcopy(tourney_matchups7c)\n",
    "tourney_final[\"Pts_Per_Poss_Diff\"] = scaler.fit_transform(np.array(tourney_final[\"Pts_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "tourney_final[\"Poss_Per_Game_Diff\"] = scaler.fit_transform(np.array(tourney_final[\"Poss_Per_Game_Diff\"]).reshape(-1,1))\n",
    "tourney_final[\"Bad_Per_Poss_Diff\"] = scaler.fit_transform(np.array(tourney_final[\"Bad_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "tourney_final[\"PPP_SD_Diff\"] = scaler.fit_transform(np.array(tourney_final[\"PPP_SD_Diff\"]).reshape(-1,1))\n",
    "tourney_final[\"Opp_Pts_Per_Poss_Diff\"] = scaler.fit_transform(np.array(tourney_final[\"Opp_Pts_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "\n",
    "# Get X predictor variables for 2021 Tourney\n",
    "X_features = [\"Pts_Per_Poss_Diff\",\"Opp_Pts_Per_Poss_Diff\",\"Poss_Per_Game_Diff\",\"Location\",\"PPP_SD_Diff\",\"Bad_Per_Poss_Diff\"]\n",
    "tourney_X_test = np.array(tourney_final[X_features])\n",
    "\n",
    "# Display samples of X and Y data\n",
    "print(\"Features used for modeling:\")\n",
    "print(X_features)\n",
    "print(\" \")\n",
    "print(\"Sample of feature values in 2021 tourney test set:\")\n",
    "print(tourney_X_test[0:10])\n",
    "print(\" \")\n",
    "print(len(tourney_X_test))\n",
    "\n",
    "# Predict probabilities using Logistic Regression\n",
    "tourney_lr_proba = lr1.predict_proba(tourney_X_test)[:,1]\n",
    "tourney_lr_pred = lr1.predict(tourney_X_test)\n",
    "\n",
    "print(tourney_lr_proba)\n",
    "print(tourney_lr_proba.shape)\n",
    "print(tourney_lr_pred)\n",
    "print(min(tourney_lr_proba))\n",
    "print(max(tourney_lr_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matchups with lowest predicted probabilities to win for Team 1: \n",
      "          Team1_Name Team2_Name  Team1_Seed  Team2_Seed  Team1_Win_Proba\n",
      "173   Appalachian St    Gonzaga          16           1         0.019991\n",
      "1946     TX Southern   Virginia          16           4         0.020646\n",
      "321         Hartford       Iowa          16           2         0.024184\n",
      "1912        Hartford   Virginia          16           4         0.028075\n",
      "188       Georgetown    Gonzaga          12           1         0.028201\n",
      "1927      Norfolk St   Virginia          16           4         0.031496\n",
      "302   Appalachian St       Iowa          16           2         0.033782\n",
      "30    Appalachian St    Colgate          16          14         0.034235\n",
      "324             Iona       Iowa          15           2         0.036592\n",
      "1885     TX Southern  Villanova          16           5         0.036800\n",
      "8     Appalachian St     Baylor          16           1         0.036872\n",
      "177          Clemson    Gonzaga           7           1         0.037736\n",
      "801         Hartford    Ohio St          16           2         0.037743\n",
      "1893  Appalachian St   Virginia          16           4         0.039155\n",
      "486         Hartford   Michigan          16           1         0.039175\n",
      "1926    Mt St Mary's   Virginia          16           4         0.041796\n",
      "816       Norfolk St    Ohio St          16           2         0.042289\n",
      "1915            Iona   Virginia          15           4         0.042393\n",
      "762         Hartford       Ohio          16          13         0.042469\n",
      "171      Abilene Chr    Gonzaga          14           1         0.042709\n",
      "178     Cleveland St    Gonzaga          15           1         0.046261\n",
      "274         Hartford   Illinois          16           1         0.047183\n",
      "317       Georgetown       Iowa          12           2         0.047381\n",
      "777       Norfolk St       Ohio          16          13         0.047557\n",
      "172          Alabama    Gonzaga           2           1         0.048868\n",
      "1925     Morehead St   Virginia          14           4         0.049621\n",
      "1851        Hartford  Villanova          16           5         0.049746\n",
      "252         Hartford    Houston          16           2         0.049906\n",
      "782   Appalachian St    Ohio St          16           2         0.052432\n",
      "467   Appalachian St   Michigan          16           1         0.054391\n",
      " \n",
      "Matchups with highest predicted probabilities to win for Team 1: \n",
      "     Team1_Name    Team2_Name  Team1_Seed  Team2_Seed  Team1_Win_Proba\n",
      "1100    Gonzaga       Rutgers           1          10         0.942395\n",
      "1512    Liberty   TX Southern          13          16         0.943768\n",
      "1497      Drake   TX Southern          11          16         0.944753\n",
      "280      Baylor          Iona           1          15         0.945061\n",
      "599      Baylor  Mt St Mary's           1          16         0.945825\n",
      "284     Colgate          Iona          14          15         0.948922\n",
      "1507    Houston   TX Southern           2          16         0.949141\n",
      "603     Colgate  Mt St Mary's          14          16         0.949635\n",
      "620        Iowa  Mt St Mary's           2          16         0.950291\n",
      "1508   Illinois   TX Southern           1          16         0.951913\n",
      "1789    Gonzaga           VCU           1          10         0.954976\n",
      "1524       Ohio   TX Southern          13          16         0.956714\n",
      "515     Gonzaga   Michigan St           1          11         0.957270\n",
      "634      Baylor    Norfolk St           1          16         0.959045\n",
      "1516   Michigan   TX Southern           1          16         0.960068\n",
      "1525    Ohio St   TX Southern           2          16         0.961527\n",
      "638     Colgate    Norfolk St          14          16         0.961963\n",
      "655        Iowa    Norfolk St           2          16         0.962465\n",
      "214      Baylor      Hartford           1          16         0.963454\n",
      "2099    Gonzaga    Wichita St           1          11         0.963500\n",
      "580     Gonzaga   Morehead St           1          14         0.964755\n",
      "218     Colgate      Hartford          14          16         0.966069\n",
      "295     Gonzaga          Iona           1          15         0.969955\n",
      "614     Gonzaga  Mt St Mary's           1          16         0.970384\n",
      "1489     Baylor   TX Southern           1          16         0.973062\n",
      "1493    Colgate   TX Southern          14          16         0.975008\n",
      "1510       Iowa   TX Southern           2          16         0.975341\n",
      "649     Gonzaga    Norfolk St           1          16         0.977752\n",
      "229     Gonzaga      Hartford           1          16         0.980189\n",
      "1504    Gonzaga   TX Southern           1          16         0.985464\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Print all possible tourney matchups' predicted results\n",
    "\n",
    "tourney_matchups8a = pd.DataFrame(data={\"Team1\":tourney_final[\"Team1\"], \"Team2\":tourney_final[\"Team2\"],\n",
    "                                        \"Team1_Win_Pred\":tourney_lr_pred, \"Team1_Win_Proba\":tourney_lr_proba})\n",
    "tourney_matchups8b = tourney_matchups8a.merge(tourney_seeds, left_on=\"Team1\", right_on=\"TeamID\")\n",
    "tourney_matchups8c = copy.deepcopy(tourney_matchups8b[[\"Team1\",\"Team2\",\"Team1_Win_Pred\",\"Team1_Win_Proba\",\"TeamName\",\"seed_line\"]])\n",
    "tourney_matchups8c.columns = [\"Team1\",\"Team2\",\"Team1_Win_Pred\",\"Team1_Win_Proba\",\"Team1_Name\",\"Team1_Seed\"]\n",
    "\n",
    "tourney_matchups8d = tourney_matchups8c.merge(tourney_seeds, left_on=\"Team2\", right_on=\"TeamID\")\n",
    "tourney_matchups8e = copy.deepcopy(tourney_matchups8d[[\"Team1\",\"Team2\",\"Team1_Name\",\"TeamName\",\"Team1_Seed\",\"seed_line\",\"Team1_Win_Pred\",\"Team1_Win_Proba\"]])\n",
    "tourney_matchups8e.columns = [\"Team1\",\"Team2\",\"Team1_Name\",\"Team2_Name\",\"Team1_Seed\",\"Team2_Seed\",\"Team1_Win_Pred\",\"Team1_Win_Proba\"]\n",
    "tourney_matchups8 = copy.deepcopy(tourney_matchups8e.sort_values(\"Team1_Win_Proba\"))\n",
    "\n",
    "print(\"Matchups with lowest predicted probabilities to win for Team 1: \")\n",
    "print(tourney_matchups8[[\"Team1_Name\",\"Team2_Name\",\"Team1_Seed\",\"Team2_Seed\",\"Team1_Win_Proba\"]].head(30))\n",
    "print(\" \")\n",
    "print(\"Matchups with highest predicted probabilities to win for Team 1: \")\n",
    "print(tourney_matchups8[[\"Team1_Name\",\"Team2_Name\",\"Team1_Seed\",\"Team2_Seed\",\"Team1_Win_Proba\"]].tail(30))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID  Team1_Win_Probability   Team1_Name      Team2_Name  \\\n",
      "0   2021_1101_1104               0.423454  Abilene Chr         Alabama   \n",
      "1   2021_1101_1111               0.649109  Abilene Chr  Appalachian St   \n",
      "3   2021_1101_1116               0.336622  Abilene Chr        Arkansas   \n",
      "6   2021_1101_1124               0.077261  Abilene Chr          Baylor   \n",
      "10  2021_1101_1140               0.216263  Abilene Chr             BYU   \n",
      "15  2021_1101_1155               0.490390  Abilene Chr         Clemson   \n",
      "21  2021_1101_1156               0.437570  Abilene Chr    Cleveland St   \n",
      "28  2021_1101_1159               0.071950  Abilene Chr         Colgate   \n",
      "36  2021_1101_1160               0.186198  Abilene Chr        Colorado   \n",
      "45  2021_1101_1163               0.298519  Abilene Chr     Connecticut   \n",
      "\n",
      "    Team1_Seed  Team2_Seed  \n",
      "0           14           2  \n",
      "1           14          16  \n",
      "3           14           3  \n",
      "6           14           1  \n",
      "10          14           6  \n",
      "15          14           7  \n",
      "21          14          15  \n",
      "28          14          14  \n",
      "36          14           5  \n",
      "45          14           7  \n"
     ]
    }
   ],
   "source": [
    "# Convert to Kaggle submission format\n",
    "tourney_matchups8x = copy.deepcopy(tourney_matchups8.sort_values([\"Team1\",\"Team2\"]))\n",
    "tourney_matchups8x[\"ID\"] = \"2021_\" + tourney_matchups8x[\"Team1\"].astype(str) + \"_\" + tourney_matchups8x[\"Team2\"].astype(str)\n",
    "tourney_matchups9 = tourney_matchups8x[[\"ID\",\"Team1_Win_Proba\",\"Team1_Name\",\"Team2_Name\",\"Team1_Seed\",\"Team2_Seed\"]]\n",
    "tourney_matchups9.columns = [\"ID\",\"Team1_Win_Probability\",\"Team1_Name\",\"Team2_Name\",\"Team1_Seed\",\"Team2_Seed\"]\n",
    "print(tourney_matchups9.head(10))\n",
    "\n",
    "# Write submission to CSV\n",
    "# tourney_matchups9.to_csv(\"RT_bracket_predictions_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID  Result\n",
      "0   2021_1211_1313       1\n",
      "1   2021_1281_1328       0\n",
      "2   2021_1166_1364       1\n",
      "3   2021_1325_1438       1\n",
      "4   2021_1179_1425       0\n",
      "..             ...     ...\n",
      "58  2021_1116_1124       0\n",
      "59  2021_1222_1333       1\n",
      "60  2021_1211_1417       1\n",
      "61  2021_1124_1222       1\n",
      "62  2021_1124_1211       1\n",
      "\n",
      "[63 rows x 2 columns]\n",
      "                ID  Team1_Win_Probability  Result\n",
      "0   2021_1211_1313               0.977752       1\n",
      "1   2021_1281_1328               0.326750       0\n",
      "2   2021_1166_1364               0.429712       1\n",
      "3   2021_1325_1438               0.355202       1\n",
      "4   2021_1179_1425               0.617178       0\n",
      "..             ...                    ...     ...\n",
      "58  2021_1116_1124               0.122473       0\n",
      "59  2021_1222_1333               0.743353       1\n",
      "60  2021_1211_1417               0.851561       1\n",
      "61  2021_1124_1222               0.620808       1\n",
      "62  2021_1124_1211               0.310674       1\n",
      "\n",
      "[63 rows x 3 columns]\n",
      " \n",
      "Kaggle score is: \n",
      "0.5947489466519752\n"
     ]
    }
   ],
   "source": [
    "# Kaggle scoring function\n",
    "def logloss(prob_pred, results):\n",
    "    score1 = 0\n",
    "    for i in range(len(prob_pred)):\n",
    "        game_score = results[i]*np.log(prob_pred[i]) + (1-results[i])*np.log(1-prob_pred[i])\n",
    "        score1 += game_score\n",
    "    score2 = score1 * -1 / len(prob_pred)\n",
    "    return score2\n",
    "\n",
    "# Replicate Kaggle scoring results\n",
    "results1a = pd.read_csv(\"ncaa_tourney_2021_results1a.csv\")\n",
    "results1b = results1a.merge(tourney_matchups9, left_on=\"ID\", right_on=\"ID\")\n",
    "results1c = copy.deepcopy(results1b[[\"ID\",\"Team1_Win_Probability\",\"Result\"]])\n",
    "\n",
    "prob_pred_test2 = list(results1c[\"Team1_Win_Probability\"])\n",
    "results_test2 = list(results1c[\"Result\"])\n",
    "print(\" \")\n",
    "print(\"Kaggle score is: \")\n",
    "print(logloss(prob_pred_test2, results_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used for modeling:\n",
      "['Pts_Per_Poss_Diff', 'Opp_Pts_Per_Poss_Diff', 'Poss_Per_Game_Diff', 'Location', 'PPP_SD_Diff', 'Bad_Per_Poss_Diff']\n",
      " \n",
      "Sample of feature values in 2019 tourney test set:\n",
      "[[ 1.61877055 -0.01718817  0.66770211  0.          1.98376456 -0.34222466]\n",
      " [ 0.90573556  2.74694867 -1.17539659  0.          0.77529405 -0.18763382]\n",
      " [ 0.14195541  0.6939942  -0.13024103  0.          0.31086776  1.11447223]\n",
      " [ 1.20038186  1.88277715 -0.39049271  0.          0.13603582 -2.94751593]\n",
      " [ 0.11579035  1.33969717  0.09038169  0.          0.43911932  1.82236762]\n",
      " [ 0.77867563 -0.97010454 -0.51068472  0.          0.39670841  0.20038406]\n",
      " [-0.9390798   0.53696756 -1.75750722  0.         -1.08268294  1.84622078]\n",
      " [-0.19336099  2.25047584  0.7690598   0.         -0.38974563  1.05071093]\n",
      " [-1.81956813 -0.38088574 -0.9967474   0.          1.07195577  2.16549824]\n",
      " [-0.75977768  0.50074258  0.70242212  0.         -0.79442864  1.70166331]]\n",
      " \n",
      "Kaggle score is: \n",
      "0.5964961995839146\n",
      "F1 Score - 2019 Tourney Results: 0.7324227078891259\n"
     ]
    }
   ],
   "source": [
    "# Get 2019 tourney matchups data\n",
    "tourney_hist_df = pd.read_csv(\"2021_Data/MNCAATourneyCompactResults.csv\")\n",
    "tourney_hist_df2 = copy.deepcopy(tourney_hist_df[tourney_hist_df[\"Season\"]==2019])\n",
    "\n",
    "wteam_2019 = list(tourney_hist_df2[\"WTeamID\"])\n",
    "lteam_2019 = list(tourney_hist_df2[\"LTeamID\"])\n",
    "\n",
    "result_2019 = []\n",
    "team1_2019 = []\n",
    "team2_2019 = []\n",
    "for i in range(len(wteam_2019)):\n",
    "    if wteam_2019[i] < lteam_2019[i]:\n",
    "        result_2019.append(1)\n",
    "        team1_2019.append(wteam_2019[i])\n",
    "        team2_2019.append(lteam_2019[i])\n",
    "    else:\n",
    "        result_2019.append(0)\n",
    "        team1_2019.append(lteam_2019[i])\n",
    "        team2_2019.append(wteam_2019[i])\n",
    "    \n",
    "\n",
    "# Get 2019 regular season data only\n",
    "team_agg2019 = copy.deepcopy(team_agg5[team_agg5[\"Season\"]==2019])\n",
    "opp_agg2019 = copy.deepcopy(opp_agg2[opp_agg2[\"Season\"]==2019])\n",
    "\n",
    "tourney_2019 = pd.DataFrame(data={\"Team1\":team1_2019, \"Team2\":team2_2019, \"Team1_Win\":result_2019})\n",
    "\n",
    "# Using 2019 tourney matchups, add Team 1 points per possession, possessions per game, bad plays per possession, PPP_SD\n",
    "tourney_2019a = tourney_2019.merge(team_agg2019, how='left', left_on=\"Team1\", right_on=\"TeamID\")\n",
    "tourney_2019b = copy.deepcopy(tourney_2019a[[\"Team1\",\"Team2\",\"Team1_Win\",\"Pts_Per_Poss\",\"Poss_Per_Game\",\"Bad_Per_Poss\",\"Team_PPP_SD\"]])\n",
    "tourney_2019b.columns = [\"Team1\",\"Team2\",\"Team1_Win\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\"]\n",
    "\n",
    "# Using 2019 tourney matchups, add Team 2 points per possession, possessions per game, bad plays per possession, PPP_SD\n",
    "tourney_2019c = tourney_2019b.merge(team_agg2019, how='left', left_on=\"Team2\", right_on=\"TeamID\")\n",
    "tourney_2019d = copy.deepcopy(tourney_2019c[[\"Team1\",\"Team2\",\"Team1_Win\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\n",
    "                                                 \"Pts_Per_Poss\",\"Poss_Per_Game\",\"Bad_Per_Poss\",\"Team_PPP_SD\"]])\n",
    "tourney_2019d.columns = [\"Team1\",\"Team2\",\"Team1_Win\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\n",
    "                         \"T2_Pts_Per_Poss\",\"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\"]\n",
    "\n",
    "# Using 2019 tourney matchups, add Team 1 and Team 2 opponent points per possession\n",
    "tourney_2019e = tourney_2019d.merge(opp_agg2021, how='left', left_on=\"Team1\", right_on=\"TeamID\")\n",
    "tourney_2019f = copy.deepcopy(tourney_2019e[[\"Team1\",\"Team2\",\"Team1_Win\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\n",
    "                                             \"T2_Pts_Per_Poss\",\"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\",\"Opp_Pts_Per_Poss\"]])\n",
    "tourney_2019f.columns = [\"Team1\",\"Team2\",\"Team1_Win\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\n",
    "                             \"T2_Pts_Per_Poss\",\"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\",\"T1_Opp_Pts_Per_Poss\"]\n",
    "tourney_2019g = tourney_2019f.merge(opp_agg2021, how='left', left_on=\"Team2\", right_on=\"TeamID\")\n",
    "tourney_2019h = copy.deepcopy(tourney_2019g[[\"Team1\",\"Team2\",\"Team1_Win\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\"T2_Pts_Per_Poss\",\n",
    "                                             \"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\",\"T1_Opp_Pts_Per_Poss\",\"Opp_Pts_Per_Poss\"]])\n",
    "tourney_2019h.columns = [\"Team1\",\"Team2\",\"Team1_Win\",\"T1_Pts_Per_Poss\",\"T1_Poss_Per_Game\",\"T1_Bad_Per_Poss\",\"T1_PPP_SD\",\"T2_Pts_Per_Poss\",\n",
    "                         \"T2_Poss_Per_Game\",\"T2_Bad_Per_Poss\",\"T2_PPP_SD\",\"T1_Opp_Pts_Per_Poss\",\"T2_Opp_Pts_Per_Poss\"]\n",
    "\n",
    "# Give neutral location for each matchup\n",
    "tourney_2019h[\"Location\"] = 0\n",
    "\n",
    "# Calculate points per possession, possessions per game, bad plays per possession, opponent points per possession difference from Team 1 perspective\n",
    "tourney_2019h[\"Pts_Per_Poss_Diff\"] = tourney_2019h[\"T1_Pts_Per_Poss\"] - tourney_2019h[\"T2_Pts_Per_Poss\"]\n",
    "tourney_2019h[\"Poss_Per_Game_Diff\"] = tourney_2019h[\"T1_Poss_Per_Game\"] - tourney_2019h[\"T2_Poss_Per_Game\"]\n",
    "tourney_2019h[\"Bad_Per_Poss_Diff\"] = tourney_2019h[\"T1_Bad_Per_Poss\"] - tourney_2019h[\"T2_Bad_Per_Poss\"]\n",
    "tourney_2019h[\"PPP_SD_Diff\"] = tourney_2019h[\"T1_PPP_SD\"] - tourney_2019h[\"T2_PPP_SD\"]\n",
    "tourney_2019h[\"Opp_Pts_Per_Poss_Diff\"] = tourney_2019h[\"T1_Opp_Pts_Per_Poss\"] - tourney_2019h[\"T2_Opp_Pts_Per_Poss\"]\n",
    "tourney_2019h.fillna(0, inplace=True)\n",
    "\n",
    "# Transform feature values to standardized normal scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "tourney_2019_final = copy.deepcopy(tourney_2019h)\n",
    "tourney_2019_final[\"Pts_Per_Poss_Diff\"] = scaler.fit_transform(np.array(tourney_2019_final[\"Pts_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "tourney_2019_final[\"Poss_Per_Game_Diff\"] = scaler.fit_transform(np.array(tourney_2019_final[\"Poss_Per_Game_Diff\"]).reshape(-1,1))\n",
    "tourney_2019_final[\"Bad_Per_Poss_Diff\"] = scaler.fit_transform(np.array(tourney_2019_final[\"Bad_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "tourney_2019_final[\"PPP_SD_Diff\"] = scaler.fit_transform(np.array(tourney_2019_final[\"PPP_SD_Diff\"]).reshape(-1,1))\n",
    "tourney_2019_final[\"Opp_Pts_Per_Poss_Diff\"] = scaler.fit_transform(np.array(tourney_2019_final[\"Opp_Pts_Per_Poss_Diff\"]).reshape(-1,1))\n",
    "\n",
    "# Get X predictor variables for 2021 Tourney\n",
    "X_features_2019 = [\"Pts_Per_Poss_Diff\",\"Opp_Pts_Per_Poss_Diff\",\"Poss_Per_Game_Diff\",\"Location\",\"PPP_SD_Diff\",\"Bad_Per_Poss_Diff\"]\n",
    "tourney_2019_X_test = np.array(tourney_2019_final[X_features_2019])\n",
    "\n",
    "# Display samples of X and Y data\n",
    "print(\"Features used for modeling:\")\n",
    "print(X_features_2019)\n",
    "print(\" \")\n",
    "print(\"Sample of feature values in 2019 tourney test set:\")\n",
    "print(tourney_2019_X_test[0:10])\n",
    "\n",
    "# Predict probabilities using Logistic Regression\n",
    "tourney_2019_lr_proba = lr1.predict_proba(tourney_2019_X_test)[:,1]\n",
    "tourney_2019_lr_pred = lr1.predict(tourney_2019_X_test)\n",
    "\n",
    "# Kaggle scoring\n",
    "prob_pred_2019 = list(tourney_2019_lr_proba)\n",
    "print(\" \")\n",
    "print(\"Kaggle score is: \")\n",
    "print(logloss(prob_pred_2019, result_2019))\n",
    "\n",
    "print(\"F1 Score - 2019 Tourney Results:\", f1_score(result_2019, tourney_2019_lr_pred , average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
